---
title: "Uncensored Completions"
openapi: 'POST /completions'
description: 'The Uncensored Completions endpoint generates responses based on provided prompts without restrictions, and supports OpenAI SDKs and uses Bearer token authentication.'
---

## Request[â€‹](#request "Direct link to Request")

```curl curl
curl -X POST https://modelslab.com/api/uncensored-chat/v1/completions \  
-H "Authorization: Bearer $MODELSLAB_API_KEY" \  
-H "Content-Type: application/json"
```


## Body
```json json
{
    "prompt": "Write a tagline for an ice cream shop.",
    "model": ""
}
```

## OpenAI SDK
This endpoint offers compatibility with the OpenAI SDKs to support developers and their apps with minimal changes. 
Once you update the base URL, you can start using the SDKs to make calls to Modelslab with API key.

<Steps>
  <Step title="Import the package">
    You can import the OpenAI python package into your python application and change the base URL and API key.

    `pip install openai`
  </Step>
  <Step title="Python code">
   ```python python
        import os
        from openai import OpenAI

        MODELSLAB_API_KEY = os.getenv("MODELSLAB_API_KEY")
        client = OpenAI(
            api_key=MODELSLAB_API_KEY,
            base_url="https://modelslab.com/api/uncensored-chat/v1",
        )

        response = client.completions.create(
            model="ModelsLab/Llama-3.1-8b-Uncensored-Dare",
            prompt="Write a tagline for an ice cream shop."
        )

        print(response.choices[0].text)
    ```
  </Step>
  <Step title="Response">
    
   ```json json
        {
            "object": "text_completion",
            "created": 1732624363,
            "model": "ModelsLab/Llama-3.1-8b-Uncensored-Dare",
            "choices": [
                {
                    "text": "\"Indulge in our destructive addiction of ice cream.\"",
                    "index": 0,
                    "logprobs": null,
                    "finish_reason": "length",
                    "stop_reason": null,
                    "prompt_logprobs": null
                }
            ],
            "usage": {
                "prompt_tokens": 122,
                "completion_tokens": 13,
                "total_tokens": 135
            }
        }
    ```
  </Step>
</Steps>