---
title: "Enterprise: Inpainting Endpoint"
---

## Overview[​](#overview "Direct link to Overview")

Enterprise Inpainting endpoint is used to change (inpaint) some part of an image according to specific requirements, based on trained or on public models. Pass the appropriate request parameters to the endpoint.

You can also add your description of the desired result by passing prompt and negative prompt.

![Inpainting endpoint result](\images\enterprise-api\text-to-image\assets\images\inpainting-8bb5f9bb4dc5d5307f0fd83248dfc296.jpg)

## Request[​](#request "Direct link to Request")

```
--request POST 'https://modelslab.com/api/v1/enterprise/inpaint' \
```

Make a `POST` request to [https://modelslab.com/api/v1/enterprise/inpaint](https://modelslab.com/api/v1/enterprise/inpaint) endpoint and pass the required parameters as a request body.

Watch the how-to video to see it in action.

## Attributes[​](#attributes "Direct link to Attributes")

| Parameter                 | Description                                                                                                                                               |
| :------------------------ | :-------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **key**                   | Your enterprise API Key used for request authorization                                                                                                    |
| **model\_id**             | The ID of the model to be used. It can be public or your trained model.                                                                                   |
| **prompt**                | Text prompt with description of the things you want in the image to be generated                                                                          |
| **negative\_prompt**      | Items you don't want in the image                                                                                                                         |
| **init\_image**           | Link to the Initial Image                                                                                                                                 |
| **mask\_image**           | Link to the mask image for inpainting                                                                                                                     |
| **width**                 | Max Height: Width: 1024x1024                                                                                                                              |
| **height**                | Max Height: Width: 1024x1024                                                                                                                              |
| **samples**               | Number of images to be returned in response. The maximum value is 4.                                                                                      |
| **num\_inference\_steps** | Number of denoising steps, The value accepts 21,31,41.                                                                                                    |
| **safety\_checker**       | A checker for NSFW images. If such an image is detected, it will be replaced by a blank image; default: yes, options: yes/no                              |
| **safety\_checker\_type** | Modify image if NSFW images are found; **default**: sensitive\_content\_text, **options**: blur/sensitive\_content\_text/pixelate/black                   |
| **enhance\_prompt**       | Enhance prompts for better results; **default**: yes, **options**: yes/no                                                                                 |
| **guidance\_scale**       | Scale for classifier-free guidance (minimum: 1; maximum: 20)                                                                                              |
| **strength**              | Prompt strength when using **init** image. 1.0 corresponds to full destruction of information in the init image.                                          |
| **tomesd**                | Enable tomesd to generate images: gives really fast results, **default**: yes, **options**: yes/no                                                        |
| **use\_karras\_sigmas**   | Use keras sigmas to generate images. gives nice results, **default**: yes, **options**: yes/no                                                            |
| **algorithm\_type**       | Used in DPMSolverMultistepScheduler scheduler, **default**: none, **options**: dpmsolver+++                                                               |
| **vae**                   | Use custom vae in generating images **default**: null                                                                                                     |
| **lora\_strength**        | Specify the strength of the LoRa model you're using. If using multiple LoRa, provide each value as a comma-separated range from minimum 0.1 to maximum 1. |
| **lora\_model**           | Multi lora is supported, pass comma saparated values . Example contrast-fix,yae-miko-genshin                                                              |
| **scheduler**             | Use it to set a [scheduler](#schedulers).                                                                                                                 |
| **seed**                  | Seed is used to reproduce results, same seed will give you same image in return again. Pass *null* for a random number.                                   |
| **webhook**               | Set an URL to get a POST API call once the image generation is complete.                                                                                  |
| **track\_id**             | This ID is returned in the response to the webhook API call. This will be used to identify the webhook request.                                           |
| **clip\_skip**            | Clip Skip (minimum: 1; maximum: 8)                                                                                                                        |
| **base64**                | Get response as base64 string, pass init\_image, mask\_image as base64 string, to get base64 response. **default**: "no", **options**: yes/no             |
| **temp**                  | Create temp image link. This link is valid for 24 hours. **temp**: yes, **options**: yes/no                                                               |

<Info>
  To use the **load balancer**, you need to have **more than 1 server**. Pass the first server's API key, and it will handle the load balancing with the other servers.
</Info>

### Schedulers[​](#schedulers "Direct link to Schedulers")

This endpoint also supports schedulers. Use the "scheduler" parameter in the request body to pass a specific scheduler from the list below:

* DDPMScheduler
* DDIMScheduler
* PNDMScheduler
* LMSDiscreteScheduler
* EulerDiscreteScheduler
* EulerAncestralDiscreteScheduler
* DPMSolverMultistepScheduler
* HeunDiscreteScheduler
* KDPM2DiscreteScheduler
* DPMSolverSinglestepScheduler
* KDPM2AncestralDiscreteScheduler
* UniPCMultistepScheduler
* DDIMInverseScheduler
* DEISMultistepScheduler
* IPNDMScheduler
* KarrasVeScheduler
* ScoreSdeVeScheduler
* LCMScheduler

## Example[​](#example "Direct link to Example")

### Body[​](#body "Direct link to Body")

Body Raw

```
{  "key": "enterprise_api_key",  "model_id": "your_model_id",  "prompt": "a cat sitting on a bench",  "negative_prompt": null,  "init_image": "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png",  "mask_image": "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png",  "width": "512",  "height": "512",  "samples": "1",  "num_inference_steps": "30",  "safety_checker": "no",  "enhance_prompt": "yes",  "guidance_scale": 7.5,  "strength": 0.7,  "scheduler": "PNDMScheduler",  "seed": null,  "lora_model": null,  "tomesd": "yes",  "use_karras_sigmas": "yes",  "vae": null,  "lora_strength": null,  "webhook": null,  "track_id": null}
```

### Request[​](#request-1 "Direct link to Request")

* JS
* PHP
* NODE
* PYTHON
* JAVA

```
var myHeaders = new Headers();myHeaders.append("Content-Type", "application/json");var raw = JSON.stringify({  "key": "",  "model_id": "your_model_id",  "prompt": "a cat sitting on a bench",  "negative_prompt": null,  "init_image": "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png",  "mask_image": "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png",  "width": "512",  "height": "512",  "samples": "1",  "steps": "30",  "safety_checker": "no",  "enhance_prompt": "yes",  "guidance_scale": 7.5,  "strength": 0.7,  "scheduler": "PNDMScheduler",  "lora_model": null,  "tomesd": "yes",  "use_karras_sigmas": "yes",  "vae": null,  "lora_strength": null,  "seed": null,  "webhook": null,  "track_id": null});var requestOptions = {  method: 'POST',  headers: myHeaders,  body: raw,  redirect: 'follow'};fetch("https://modelslab.com/api/v1/enterprise/inpaint", requestOptions)  .then(response => response.text())  .then(result => console.log(result))  .catch(error => console.log('error', error));
```

```
<?php$payload = [  "key" => "",   "model_id" => "your_model_id",   "prompt" => "a cat sitting on a bench",   "negative_prompt" => null,   "init_image" => "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png",   "mask_image" => "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png",   "width" => "512",   "height" => "512",   "samples" => "1",   "steps" => "30",   "safety_checker" => "no",   "enhance_prompt" => "yes",   "guidance_scale" => 7.5,   "strength" => 0.7,   "scheduler" => "PNDMScheduler",  "lora_model" => null,  "tomesd" => "yes",  "use_karras_sigmas" => "yes",  "vae" => null,  "lora_strength" => null,  "seed" => null,   "webhook" => null,   "track_id" => null ];$curl = curl_init();curl_setopt_array($curl, array(  CURLOPT_URL => 'https://modelslab.com/api/v1/enterprise/inpaint',  CURLOPT_RETURNTRANSFER => true,  CURLOPT_ENCODING => '',  CURLOPT_MAXREDIRS => 10,  CURLOPT_TIMEOUT => 0,  CURLOPT_FOLLOWLOCATION => true,  CURLOPT_HTTP_VERSION => CURL_HTTP_VERSION_1_1,  CURLOPT_CUSTOMREQUEST => 'POST',  CURLOPT_POSTFIELDS =>  json_encode($payload),  CURLOPT_HTTPHEADER => array(    'Content-Type: application/json'  ),));$response = curl_exec($curl);curl_close($curl);echo $response;
```

```
var request = require('request');var options = {  'method': 'POST',  'url': 'https://modelslab.com/api/v1/enterprise/inpaint',  'headers': {    'Content-Type': 'application/json'  },  body: JSON.stringify({    "key": "",    "model_id": "your_model_id",    "prompt": "a cat sitting on a bench",    "negative_prompt": null,    "init_image": "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png",    "mask_image": "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png",    "width": "512",    "height": "512",    "samples": "1",    "steps": "30",    "safety_checker": "no",    "enhance_prompt": "yes",    "guidance_scale": 7.5,    "strength": 0.7,    "scheduler": "PNDMScheduler",    "lora_model": null,    "tomesd": "yes",    "use_karras_sigmas": "yes",    "vae": null,    "lora_strength": null,    "seed": null,    "webhook": null,    "track_id": null  })};request(options, function (error, response) {  if (error) throw new Error(error);  console.log(response.body);});
```

```
import requestsimport jsonurl = "https://modelslab.com/api/v1/enterprise/inpaint"payload = json.dumps({  "key": "",  "prompt": "a cat sitting on a bench",  "negative_prompt": None,  "init_image": "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png",  "mask_image": "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png",  "width": "512",  "height": "512",  "samples": "1",  "steps": "30",  "safety_checker": "no",  "enhance_prompt": "yes",  "guidance_scale": 7.5,  "strength": 0.7,  "scheduler": "PNDMScheduler",  "lora_model": null,  "tomesd": "yes",  "use_karras_sigmas": "yes",  "vae": None,  "lora_strength": None,  "seed": None,  "webhook": None,  "track_id": None})headers = {  'Content-Type': 'application/json'}response = requests.request("POST", url, headers=headers, data=payload)print(response.text)
```

```
OkHttpClient client = new OkHttpClient().newBuilder()  .build();MediaType mediaType = MediaType.parse("application/json");RequestBody body = RequestBody.create(mediaType, "{\n     \"key\": \"\",\n  \"model_id\": \"your_model_id\",\n  \"prompt\": \"a cat sitting on a bench\",\n  \"negative_prompt\": null,\n  \"init_image\": \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\",\n  \"mask_image\": \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\",\n  \"width\": \"512\",\n  \"height\": \"512\",\n  \"samples\": \"1\",\n  \"num_inference_steps\": \"30\",\n  \"safety_checker\": \"no\",\n  \"enhance_prompt\": \"yes\",\n  \"guidance_scale\": 7.5,\n  \"strength\": 0.7,\n  \"scheduler\": \"PNDMScheduler\",\n  \"seed\": null,\n  \"lora_model\": \"lora_model_id\",\n  \"tomesd\": \"yes\",\n  \"use_karras_sigmas\": \"yes\",\n  \"vae\": null,\n  \"lora_strength\": null,\n  \"webhook\": null,\n  \"track_id\": null\n}");Request request = new Request.Builder()  .url("https://modelslab.com/api/v1/enterprise/inpaint")  .method("POST", body)  .addHeader("Content-Type", "application/json")  .build();Response response = client.newCall(request).execute();
```

### Response[​](#response "Direct link to Response")

Example Response

```
{  "status": "success",  "generationTime": 20.970642805099487,  "id": 13446970,  "output": [    "https://pub-8b49af329fae499aa563997f5d4068a4.r2.dev/generations/dc639bd6-d605-42c7-950e-48c531124d0d-0.png"  ],  "meta": {    "prompt": " a cat sitting on a bench DSLR photography, sharp focus, Unreal Engine 5, Octane Render, Redshift, ((cinematic lighting)), f/1.4, ISO 200, 1/160s, 8K, RAW, unedited, symmetrical balance, in-frame",    "model_id": "midjourney-v4-painta",    "scheduler": "PNDMScheduler",    "safetychecker": "no",    "negative_prompt": " ((out of frame)), ((extra fingers)), mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), (((tiling))), ((naked)), ((tile)), ((fleshpile)), ((ugly)), (((abstract))), blurry, ((bad anatomy)), ((bad proportions)), ((extra limbs)), cloned face, glitchy, ((extra breasts)), ((double torso)), ((extra arms)), ((extra hands)), ((mangled fingers)), ((missing breasts)), (missing lips), ((ugly face)), ((fat)), ((extra legs))",    "W": 512,    "H": 512,    "guidance_scale": 7.5,    "init_image": "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png",    "mask_image": "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png",    "steps": 50,    "n_samples": 1,    "full_url": "no",    "upscale": "no",    "seed": 1343687916,    "outdir": "out",    "file_prefix": "dc639bd6-d605-42c7-950e-48c531124d0d"  }}
```
